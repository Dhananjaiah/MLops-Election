# Lecture 6.3 â€“ Structuring Experiments (Folders, Scripts, Configs)

## In This Lecture You Will Learn

- [x] Organize ML experiments with proper folder structure
- [x] Separate concerns (data, features, models, configs)
- [x] Use configuration files to make experiments reproducible

---

## Real-World Context

> **Story**: Lisa's team had 47 experiment folders: `churn_final`, `churn_final_v2`, `churn_REALLY_final`, `churn_jan15_test`, `churn_production_candidate`... Nobody knew which was which. When the CEO asked "Which model are we using?" it took 3 days to figure out. Then they adopted a standard structure: date-based folders, config files for every run, README for each experiment. Finding experiments went from hours to seconds. Organization isn't glamorous, but it's the difference between chaos and productivity.

In the real world, poor organization kills more ML projects than bad algorithms. A well-structured experiment setup enables fast iteration, easy comparison, and painless handoffs.

---

## Main Content

### 1. Standard ML Project Structure

```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original, immutable data
â”‚   â”œâ”€â”€ processed/              # Cleaned, transformed data
â”‚   â””â”€â”€ features/               # Engineered features
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploration.ipynb   # EDA, initial analysis
â”‚   â”œâ”€â”€ 02_modeling.ipynb      # Prototyping models
â”‚   â””â”€â”€ README.md              # Index of notebooks
â”‚
â”œâ”€â”€ src/                        # Source code (not notebooks!)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ make_dataset.py    # Data loading functions
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ build_features.py  # Feature engineering
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ train_model.py     # Training logic
â”‚       â””â”€â”€ predict_model.py   # Inference logic
â”‚
â”œâ”€â”€ models/                     # Trained model artifacts
â”‚   â”œâ”€â”€ 2024-01-15_rf_v1/
â”‚   â”‚   â”œâ”€â”€ model.pkl
â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â”œâ”€â”€ metrics.json
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ 2024-01-20_xgb_v2/
â”‚
â”œâ”€â”€ experiments/                # Experiment tracking
â”‚   â”œâ”€â”€ 2024-01-15_baseline/
â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â”œâ”€â”€ results.json
â”‚   â”‚   â””â”€â”€ notes.md
â”‚   â””â”€â”€ 2024-01-20_feature_eng/
â”‚
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ config/                     # Configuration files
â”‚   â”œâ”€â”€ default.yaml           # Default parameters
â”‚   â”œâ”€â”€ experiment1.yaml       # Experiment-specific
â”‚   â””â”€â”€ production.yaml        # Production config
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ setup.py                    # Make project pip-installable
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ Makefile                    # Common commands

```

### 2. Configuration-Driven Experiments

**Why Config Files?**
- Parameters in code = hard to track what changed
- Config files = clear history of all experiments
- Easy to run same experiment with different params

**Example config.yaml**:
```yaml
# config/experiment_2024-01-15.yaml
experiment:
  name: "churn_rf_baseline"
  date: "2024-01-15"
  author: "lisa@company.com"
  description: "Baseline Random Forest with default params"

data:
  train: "data/processed/train_2024-01-01.parquet"
  val: "data/processed/val_2024-01-01.parquet"
  test: "data/processed/test_2024-01-01.parquet"

features:
  - customer_id
  - tenure_months
  - monthly_charges
  - total_charges
  - contract_type
  - payment_method

model:
  type: "RandomForestClassifier"
  params:
    n_estimators: 100
    max_depth: 10
    min_samples_split: 5
    random_state: 42

training:
  batch_size: null  # Not applicable for RF
  epochs: null
  validation_split: 0.2
  
output:
  model_path: "models/2024-01-15_rf_v1/"
  metrics_path: "experiments/2024-01-15_baseline/metrics.json"
```

### 3. Experiment Naming Conventions

**Good Naming**:
- `2024-01-15_rf_baseline` - Date + model + purpose
- `2024-01-20_xgb_feature_eng_v2` - Clear what changed
- `2024-02-01_final_production_candidate` - Intent clear

**Bad Naming**:
- `experiment1`, `test`, `final`, `final_v2`, `final_REALLY`
- No dates, no context, unusable

**Folder Naming Pattern**:
```
YYYY-MM-DD_model-type_description/
  â”œâ”€â”€ config.yaml      # All parameters
  â”œâ”€â”€ results.json     # Metrics
  â”œâ”€â”€ model.pkl        # Trained model
  â””â”€â”€ README.md        # Notes, insights, next steps
```

### 4. Separation of Concerns

**Principle**: Each file/module has ONE job

**data/make_dataset.py**: Load and clean data only
```python
def load_raw_data(path):
    return pd.read_csv(path)

def clean_data(df):
    df = df.dropna()
    df = df[df['age'] > 0]
    return df
```

**features/build_features.py**: Feature engineering only
```python
def engineer_temporal_features(df):
    df['days_since_signup'] = (pd.Timestamp.now() - df['signup_date']).dt.days
    return df
```

**models/train_model.py**: Training logic only
```python
def train_model(X, y, config):
    model = RandomForestClassifier(**config['model']['params'])
    model.fit(X, y)
    return model
```

**scripts/run_experiment.py**: Orchestration only
```python
def main(config_path):
    config = load_config(config_path)
    data = load_raw_data(config['data']['train'])
    data = clean_data(data)
    features = engineer_features(data)
    model = train_model(features, config)
    metrics = evaluate_model(model, val_data)
    save_results(model, metrics, config)
```

---

## Diagrams

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Well-Structured ML Project                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  ðŸ“‚ project/                                                     â”‚
â”‚  â”œâ”€â”€ ðŸ“Š data/            (raw, processed, features)            â”‚
â”‚  â”œâ”€â”€ ðŸ““ notebooks/       (exploration only)                     â”‚
â”‚  â”œâ”€â”€ ðŸ’» src/             (production code)                      â”‚
â”‚  â”‚   â”œâ”€â”€ data/          (load & clean)                          â”‚
â”‚  â”‚   â”œâ”€â”€ features/      (engineer)                              â”‚
â”‚  â”‚   â””â”€â”€ models/        (train & predict)                       â”‚
â”‚  â”œâ”€â”€ ðŸ¤– models/          (saved artifacts + configs)            â”‚
â”‚  â”‚   â””â”€â”€ 2024-01-15_rf_v1/                                      â”‚
â”‚  â”‚       â”œâ”€â”€ model.pkl                                          â”‚
â”‚  â”‚       â”œâ”€â”€ config.yaml                                        â”‚
â”‚  â”‚       â””â”€â”€ metrics.json                                       â”‚
â”‚  â”œâ”€â”€ ðŸ”¬ experiments/     (experiment tracking)                  â”‚
â”‚  â”œâ”€â”€ âš™ï¸  config/          (parameter files)                      â”‚
â”‚  â””â”€â”€ âœ… tests/           (unit tests)                            â”‚
â”‚                                                                   â”‚
â”‚  Every piece has its place. Easy to navigate and maintain.      â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

![Diagram Placeholder](../../assets/diagrams/lecture-6-3-diagram.png)

> Diagram shows organized project structure with clear separation of concerns

---

## Lab / Demo

### Prerequisites

- Completed Lectures 6.1-6.2
- Cookiecutter installed (optional)

### Step-by-Step Instructions

```bash
# Step 1: Create project structure
cd project
mkdir -p data/{raw,processed,features} src/{data,features,models} models experiments config tests

# Step 2: Create a sample config file
cat > config/baseline.yaml << EOF
experiment:
  name: baseline_rf
  date: $(date +%Y-%m-%d)

model:
  type: RandomForestClassifier
  params:
    n_estimators: 100
    random_state: 42
EOF

# Step 3: Create training script
cat > src/models/train_model.py << 'EOF'
import yaml
import pickle
from sklearn.ensemble import RandomForestClassifier

def train(config_path):
    with open(config_path) as f:
        config = yaml.safe_load(f)
    
    model = RandomForestClassifier(**config['model']['params'])
    # Training logic here
    return model

if __name__ == '__main__':
    import sys
    train(sys.argv[1])
EOF

# Step 4: Run experiment
python src/models/train_model.py config/baseline.yaml
```

### Expected Output

```
Project Structure Created:
data/
  raw/
  processed/
  features/
src/
  data/
  features/
  models/
    train_model.py âœ“
models/
experiments/
config/
  baseline.yaml âœ“
tests/

Training:
Loading config: config/baseline.yaml
Experiment: baseline_rf
Date: 2024-01-15
Training Random Forest with n_estimators=100...
Model saved to: models/2024-01-15_baseline_rf/
```

### Explanation

1. **Step 1**: Set up organized folder structure
2. **Step 2**: Create config file (all parameters documented)
3. **Step 3**: Write modular training code
4. **Step 4**: Run experiment using config (fully reproducible)

---

## Common Pitfalls / Gotchas

- âš ï¸ **Pitfall 1**: Over-organizing too early. Don't create 20 folders on day 1. Grow structure as project grows.

- âš ï¸ **Pitfall 2**: Mixing code and data. Never commit data to Git. Use `.gitignore` for data folders.

- âš ï¸ **Pitfall 3**: Hard-coding paths. Use relative paths or config files. `../../data/file.csv` breaks when shared.

---

## Homework / Practice

1. **Exercise 1**: Take your current ML project (or create a toy one). Reorganize it using the structure from this lecture. Time: 1 hour.

2. **Exercise 2**: Create a config file for 3 different experiments: baseline, feature engineering, hyperparameter tuning. Run all 3 and compare results.

3. **Stretch Goal**: Use Cookiecutter Data Science template to scaffold a new project. Explore how professionals structure ML projects.

---

## Quick Quiz

1. **Why use config files instead of hard-coding parameters?**
   - A) Config files run faster
   - B) Makes experiments reproducible and trackable
   - C) Required by MLflow
   - D) Config files are easier to write

2. **What should go in the `src/` directory?**
   - A) Trained models
   - B) Raw data
   - C) Production-ready code (functions, classes)
   - D) Jupyter notebooks

3. **True or False: You should commit your `data/` folder to Git.**

<details>
<summary>Answers</summary>

1. **B** - Config files document all parameters, making experiments reproducible
2. **C** - `src/` contains production code (functions, modules), not data or notebooks
3. **False** - Data files are large and change often. Use `.gitignore` and store data externally (S3, etc.)

</details>

---

## Summary

- Standard structure: data/, src/, models/, experiments/, config/, tests/
- Separate concerns: one file/module = one responsibility
- Use config files for all parameters (not hard-coded)
- Name experiments with dates + descriptive names
- Keep notebooks for exploration, scripts for production
- Grow structure incrementallyâ€”don't over-organize on day 1

---

## Next Steps

â†’ Continue to **Lecture 6.4**: Experiment Tracking Concepts (Runs, Params, Metrics, Artifacts)

---

## Additional Resources

- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/) - Standard project template
- [Hydra](https://hydra.cc/) - Advanced configuration management
- [DVC](https://dvc.org/) - Data version control
